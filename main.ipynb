{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Instalar dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7kjn6Rr7deU"
   },
   "outputs": [],
   "source": [
    "%pip install transformers datasets peft accelerate bitsandbytes xformers unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Baixar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRtQowTg8lEp"
   },
   "outputs": [],
   "source": [
    "!wget -O \"LF-Amazon-1.3M.zip\" \"https://drive.usercontent.google.com/download?id=12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK&export=download&authuser=0&confirm=t\"\n",
    "!unzip \"LF-Amazon-1.3M.zip\"\n",
    "!gzip --decompress \"./LF-Amazon-1.3M/trn.json.gz\"\n",
    "!mv \"./LF-Amazon-1.3M/trn.json\" \"./trn.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mW2fwj087deV"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Verificar se possui CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_tv5ZUw7deW"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Treinando no dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "886bP0uV7deX"
   },
   "outputs": [],
   "source": [
    "file_path = \"trn.json\"\n",
    "\n",
    "data = []\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            data.append(json.loads(line))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Erro ao decodificar linha: {line}\")\n",
    "            print(f\"Detalhes do erro: {e}\")\n",
    "\n",
    "filtered_data = [{\"title\": entry[\"title\"], \"content\": entry[\"content\"]} for entry in data]\n",
    "\n",
    "output_file_path = \"filtered_data.json\"\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    json.dump(filtered_data, output_file, indent=4)\n",
    "\n",
    "print(f\"Arquivo filtrado salvo em: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jfbo71EZ_QDe"
   },
   "outputs": [],
   "source": [
    "# Liberar RAM\n",
    "del data\n",
    "del filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU9gfwwa7deX"
   },
   "outputs": [],
   "source": [
    "# Carregar o arquivo JSON\n",
    "with open('filtered_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Converter para DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqUTGRV37deY"
   },
   "outputs": [],
   "source": [
    "def create_prompt(row):\n",
    "    return {\n",
    "        \"input\": f\"You are a book expert and should answer any question involving this title {row['title']}\",\n",
    "        \"output\": row[\"content\"]\n",
    "    }\n",
    "\n",
    "# Aplicar ao DataFrame\n",
    "fine_tune_data = df.apply(create_prompt, axis=1)\n",
    "fine_tune_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUW0yvxS7deY"
   },
   "outputs": [],
   "source": [
    "# Dividir os dados em treinamento e validação\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar 10% dos dados para validação\n",
    "train_data, val_data = train_test_split(fine_tune_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSAT_WyB_8lJ"
   },
   "outputs": [],
   "source": [
    "# Liberar RAM\n",
    "del fine_tune_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-ZlBrBf7deY"
   },
   "outputs": [],
   "source": [
    "with open('train_data.json', 'w') as f:\n",
    "    train_data.to_json('train_data.json', orient='records', lines=True)\n",
    "\n",
    "with open('val_data.json', 'w') as f:\n",
    "    val_data.to_json('val_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up7TlqBdAVDd"
   },
   "outputs": [],
   "source": [
    "# Liberar RAM\n",
    "del train_data\n",
    "del val_data\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obuhy7YM7deY"
   },
   "outputs": [],
   "source": [
    "# Carregar os datasets\n",
    "train_dataset = Dataset.from_json(\"train_data.json\")\n",
    "val_dataset = Dataset.from_json(\"val_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQHojQNX7deZ"
   },
   "outputs": [],
   "source": [
    "# Escolha do modelo\n",
    "model_name = \"t5-small\"  # Altere para o modelo desejado, como \"mistralai/Mistral-7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Mover o modelo para o dispositivo\n",
    "model = model.to(device)  # Modificação: Move o modelo para GPU ou CPU\n",
    "print(f\"Modelo carregado no dispositivo: {model.device}\")\n",
    "\n",
    "# Função de tokenização\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"input\"],\n",
    "        text_target=examples[\"output\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256  # Modificação: Reduz o comprimento máximo para economizar memória\n",
    "    )\n",
    "\n",
    "# Tokenizar os datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3OLB16_Ba7B"
   },
   "outputs": [],
   "source": [
    "# Liberar RAM\n",
    "del train_dataset\n",
    "del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzXDQbe0H9Hy"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "tokenized_train_dataset.save_to_disk(\"tokenized_train_dataset\")\n",
    "tokenized_val_dataset.save_to_disk(\"tokenized_val_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXOt7tA2IAXZ"
   },
   "outputs": [],
   "source": [
    "# Read from saved tokenized\n",
    "tokenized_train_dataset = Dataset.load_from_disk(\"tokenized_train_dataset\")\n",
    "tokenized_val_dataset = Dataset.load_from_disk(\"tokenized_val_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2dHBLud7deZ"
   },
   "outputs": [],
   "source": [
    "# Configurações de treinamento\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=2,  # Modificação: Reduz o batch size para evitar OOM\n",
    "    gradient_accumulation_steps=4,  # Modificação: Acumula gradientes para simular batches maiores\n",
    "    num_train_epochs=3,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Modificação: Habilitar Mixed Precision Training\n",
    "    logging_dir='./logs',\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6z2Ybmek7dea"
   },
   "outputs": [],
   "source": [
    "# Criar o Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eFaYkqv7dea"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSsNakf4Mbre"
   },
   "outputs": [],
   "source": [
    "# Save trainer\n",
    "trainer.save_model(\"./results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0INlwmHxMjBd"
   },
   "outputs": [],
   "source": [
    "# Load trainer\n",
    "trainer = Seq2SeqTrainer.from_pretrained(\"./results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twAaBXBx7dea"
   },
   "outputs": [],
   "source": [
    "# Função para perguntas\n",
    "def ask_question(question, model, tokenizer, device):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Modificação: Move os dados para o dispositivo correto\n",
    "    outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=512,  # Corrigido: max_length\n",
    "    num_beams=10,  # Beam search para respostas melhores\n",
    "    no_repeat_ngram_size=2,  # Evitar repetições\n",
    "    temperature=0.7,  # Controlar aleatoriedade\n",
    "    top_k=50,  # Filtrar os 50 tokens mais prováveis\n",
    "    top_p=0.95,  # Top-p sampling para diversidade\n",
    "    do_sample=True\n",
    ")\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtQMUUmANQaL"
   },
   "outputs": [],
   "source": [
    "# Exemplo de teste\n",
    "question = input(\"Pergunta: \") # \"You are a book expert and should answer any question involving this title Collins German Unabridged Dictionary 5th Edition (Harpercollins Unabridged Dictionaries)\"\n",
    "response = ask_question(question, model, tokenizer, device)\n",
    "print(\"Pergunta:\", question)\n",
    "print(\"Resposta:\", response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
